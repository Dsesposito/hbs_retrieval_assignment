{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b781e47-2986-4c1d-b1f6-28361312aa93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: asttokens==3.0.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (3.0.0)\n",
      "Collecting certifi==2025.1.31 (from -r requirements.txt (line 2))\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting charset-normalizer==3.4.1 (from -r requirements.txt (line 3))\n",
      "  Using cached charset_normalizer-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Requirement already satisfied: comm==0.2.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.2.2)\n",
      "Collecting contourpy==1.3.0 (from -r requirements.txt (line 5))\n",
      "  Using cached contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler==0.12.1 (from -r requirements.txt (line 6))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: exceptiongroup==1.2.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (1.2.2)\n",
      "Requirement already satisfied: executing==2.2.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (2.2.0)\n",
      "Collecting filelock==3.18.0 (from -r requirements.txt (line 9))\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fonttools==4.56.0 (from -r requirements.txt (line 10))\n",
      "  Using cached fonttools-4.56.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
      "Collecting fsspec==2025.3.0 (from -r requirements.txt (line 11))\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub==0.29.3 (from -r requirements.txt (line 12))\n",
      "  Using cached huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting idna==3.10 (from -r requirements.txt (line 13))\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: importlib_metadata==8.6.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 14)) (8.6.1)\n",
      "Collecting importlib_resources==6.5.2 (from -r requirements.txt (line 15))\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: jedi==0.19.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 16)) (0.19.2)\n",
      "Collecting Jinja2==3.1.6 (from -r requirements.txt (line 17))\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting joblib==1.4.2 (from -r requirements.txt (line 18))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting MarkupSafe==3.0.2 (from -r requirements.txt (line 19))\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting matplotlib==3.9.4 (from -r requirements.txt (line 20))\n",
      "  Using cached matplotlib-3.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 21)) (0.1.7)\n",
      "Collecting mpmath==1.3.0 (from -r requirements.txt (line 22))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 23)) (1.6.0)\n",
      "Collecting networkx==3.2.1 (from -r requirements.txt (line 24))\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting numpy==2.0.2 (from -r requirements.txt (line 25))\n",
      "  Using cached numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from -r requirements.txt (line 26))\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from -r requirements.txt (line 27))\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from -r requirements.txt (line 28))\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from -r requirements.txt (line 29))\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from -r requirements.txt (line 30))\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from -r requirements.txt (line 31))\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from -r requirements.txt (line 32))\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from -r requirements.txt (line 33))\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from -r requirements.txt (line 34))\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from -r requirements.txt (line 35))\n",
      "  Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from -r requirements.txt (line 36))\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from -r requirements.txt (line 37))\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from -r requirements.txt (line 38))\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: packaging==24.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 39)) (24.2)\n",
      "Collecting pandas==2.2.2 (from -r requirements.txt (line 40))\n",
      "  Using cached pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: parso==0.8.4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 41)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 42)) (4.9.0)\n",
      "Collecting pillow==11.1.0 (from -r requirements.txt (line 43))\n",
      "  Using cached pillow-11.1.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: platformdirs==4.3.7 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 44)) (4.3.7)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.50 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 45)) (3.0.50)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 46)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 47)) (0.2.3)\n",
      "Requirement already satisfied: Pygments==2.19.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 48)) (2.19.1)\n",
      "Collecting pyparsing==3.2.1 (from -r requirements.txt (line 49))\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pytz==2025.1 (from -r requirements.txt (line 50))\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting PyYAML==6.0.2 (from -r requirements.txt (line 51))\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: pyzmq==26.3.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 52)) (26.3.0)\n",
      "Collecting regex==2024.11.6 (from -r requirements.txt (line 53))\n",
      "  Using cached regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests==2.32.3 (from -r requirements.txt (line 54))\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting safetensors==0.5.3 (from -r requirements.txt (line 55))\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting scikit-learn==1.6.1 (from -r requirements.txt (line 56))\n",
      "  Using cached scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting scipy==1.13.1 (from -r requirements.txt (line 57))\n",
      "  Using cached scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting seaborn==0.13.2 (from -r requirements.txt (line 58))\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting sentence-transformers==3.4.1 (from -r requirements.txt (line 59))\n",
      "  Using cached sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: six==1.17.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 60)) (1.17.0)\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 61)) (0.6.3)\n",
      "Collecting sympy==1.13.1 (from -r requirements.txt (line 62))\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting threadpoolctl==3.6.0 (from -r requirements.txt (line 63))\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tokenizers==0.21.1 (from -r requirements.txt (line 64))\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting torch==2.6.0 (from -r requirements.txt (line 65))\n",
      "  Using cached torch-2.6.0-cp39-cp39-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: tornado==6.4.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 66)) (6.4.2)\n",
      "Collecting tqdm==4.67.1 (from -r requirements.txt (line 67))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: traitlets==5.14.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 68)) (5.14.3)\n",
      "Collecting transformers==4.50.0 (from -r requirements.txt (line 69))\n",
      "  Using cached transformers-4.50.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting triton==3.2.0 (from -r requirements.txt (line 70))\n",
      "  Using cached triton-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 71)) (4.12.2)\n",
      "Collecting tzdata==2025.2 (from -r requirements.txt (line 72))\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting urllib3==2.3.0 (from -r requirements.txt (line 73))\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 74)) (0.2.13)\n",
      "Requirement already satisfied: zipp==3.21.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 75)) (3.21.0)\n",
      "Collecting langchain-text-splitters==0.3.7 (from -r requirements.txt (line 76))\n",
      "  Using cached langchain_text_splitters-0.3.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting einops==0.8.1 (from -r requirements.txt (line 77))\n",
      "  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib==3.9.4->-r requirements.txt (line 20))\n",
      "  Using cached kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.9/site-packages (from matplotlib==3.9.4->-r requirements.txt (line 20)) (2.9.0.post0)\n",
      "Collecting langchain-core<1.0.0,>=0.3.45 (from langchain-text-splitters==0.3.7->-r requirements.txt (line 76))\n",
      "  Using cached langchain_core-0.3.48-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain-core<1.0.0,>=0.3.45->langchain-text-splitters==0.3.7->-r requirements.txt (line 76))\n",
      "  Using cached langsmith-0.3.18-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.45->langchain-text-splitters==0.3.7->-r requirements.txt (line 76))\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.45->langchain-text-splitters==0.3.7->-r requirements.txt (line 76))\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pydantic<3.0.0,>=2.5.2 (from langchain-core<1.0.0,>=0.3.45->langchain-text-splitters==0.3.7->-r requirements.txt (line 76))\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters==0.3.7->-r requirements.txt (line 76))\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters==0.3.7->-r requirements.txt (line 76))\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters==0.3.7->-r requirements.txt (line 76))\n",
      "  Using cached orjson-3.10.16-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters==0.3.7->-r requirements.txt (line 76))\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters==0.3.7->-r requirements.txt (line 76))\n",
      "  Using cached zstandard-0.23.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters==0.3.7->-r requirements.txt (line 76))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters==0.3.7->-r requirements.txt (line 76))\n",
      "  Using cached pydantic_core-2.27.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters==0.3.7->-r requirements.txt (line 76))\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters==0.3.7->-r requirements.txt (line 76))\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters==0.3.7->-r requirements.txt (line 76))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters==0.3.7->-r requirements.txt (line 76))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)\n",
      "Using cached contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fonttools-4.56.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Using cached matplotlib-3.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Using cached pillow-11.1.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (737 kB)\n",
      "Using cached regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (780 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Using cached scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "Using cached scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached torch-2.6.0-cp39-cp39-manylinux1_x86_64.whl (766.7 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached transformers-4.50.0-py3-none-any.whl (10.2 MB)\n",
      "Using cached triton-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\n",
      "Using cached einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Using cached kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Using cached langchain_core-0.3.48-py3-none-any.whl (418 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langsmith-0.3.18-py3-none-any.whl (351 kB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached orjson-3.10.16-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached zstandard-0.23.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: triton, pytz, nvidia-cusparselt-cu12, mpmath, zstandard, urllib3, tzdata, tqdm, threadpoolctl, tenacity, sympy, sniffio, safetensors, regex, PyYAML, pyparsing, pydantic-core, pillow, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, kiwisolver, jsonpointer, joblib, importlib_resources, idna, h11, fsspec, fonttools, filelock, einops, cycler, charset-normalizer, certifi, annotated-types, scipy, requests, pydantic, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jsonpatch, Jinja2, httpcore, contourpy, anyio, scikit-learn, requests-toolbelt, nvidia-cusolver-cu12, matplotlib, huggingface-hub, httpx, torch, tokenizers, seaborn, langsmith, transformers, langchain-core, sentence-transformers, langchain-text-splitters\n",
      "Successfully installed Jinja2-3.1.6 MarkupSafe-3.0.2 PyYAML-6.0.2 annotated-types-0.7.0 anyio-4.9.0 certifi-2025.1.31 charset-normalizer-3.4.1 contourpy-1.3.0 cycler-0.12.1 einops-0.8.1 filelock-3.18.0 fonttools-4.56.0 fsspec-2025.3.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 huggingface-hub-0.29.3 idna-3.10 importlib_resources-6.5.2 joblib-1.4.2 jsonpatch-1.33 jsonpointer-3.0.0 kiwisolver-1.4.7 langchain-core-0.3.48 langchain-text-splitters-0.3.7 langsmith-0.3.18 matplotlib-3.9.4 mpmath-1.3.0 networkx-3.2.1 numpy-2.0.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 orjson-3.10.16 pandas-2.2.2 pillow-11.1.0 pydantic-2.10.6 pydantic-core-2.27.2 pyparsing-3.2.1 pytz-2025.1 regex-2024.11.6 requests-2.32.3 requests-toolbelt-1.0.0 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.13.1 seaborn-0.13.2 sentence-transformers-3.4.1 sniffio-1.3.1 sympy-1.13.1 tenacity-9.0.0 threadpoolctl-3.6.0 tokenizers-0.21.1 torch-2.6.0 tqdm-4.67.1 transformers-4.50.0 triton-3.2.0 tzdata-2025.2 urllib3-2.3.0 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Python 3.9 required\n",
    "# Use GPU to speed up embedding matrix calculation. Alternative: download the embedding matrix \n",
    "# already calculated by me from \n",
    "# https://drive.google.com/file/d/1fJ5rhqI6wBXKLVbQURj7o7ZPhxTxB_4d/view?usp=sharing and place it \n",
    "# at the same directory level as this notebook.\n",
    "# If you want to compute your own embedding matrix use a Google Colab environment with GPU.\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e43e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/desposito/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List, Literal, NewType, Dict\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2384d13-941a-4c49-b903-68c5cf55ac15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'WANDS' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# Clone the git repo that contains the data and additional information about the dataset\n",
    "!git clone https://github.com/wayfair/WANDS.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42485468-77e2-4fc3-9a70-319a70603472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define functions for product search using Tf-IDF\n",
    "def calculate_tfidf(dataframe):\n",
    "    \"\"\"\n",
    "    Calculate the TF-IDF for combined product name and description.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): DataFrame with product_id, and other product information.\n",
    "\n",
    "    Returns:\n",
    "    TfidfVectorizer, csr_matrix: TF-IDF vectorizer and TF-IDF matrix.\n",
    "    \"\"\"\n",
    "    # Combine product name and description to vectorize\n",
    "    # NOTE: Please feel free to use any combination of columns available, some columns may contain NULL values\n",
    "    combined_text = dataframe['product_name'] + ' ' + dataframe['product_description']\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    # Convert combined_text to list of unicode strings\n",
    "    tfidf_matrix = vectorizer.fit_transform(combined_text.values.astype('U'))\n",
    "    return vectorizer, tfidf_matrix\n",
    "\n",
    "def get_top_products(vectorizer, tfidf_matrix, query, top_n=10):\n",
    "    \"\"\"\n",
    "    Get top N products for a given query based on TF-IDF similarity.\n",
    "\n",
    "    Parameters:\n",
    "    vectorizer (TfidfVectorizer): Trained TF-IDF vectorizer.\n",
    "    tfidf_matrix (csr_matrix): TF-IDF matrix for the products.\n",
    "    query (str): Search query.\n",
    "    top_n (int): Number of top products to return.\n",
    "\n",
    "    Returns:\n",
    "    list: List of top N product IDs.\n",
    "    \"\"\"\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    cosine_similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "    top_product_indices = cosine_similarities.argsort()[-top_n:][::-1]\n",
    "    return top_product_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dd06913-4149-44c7-a876-787316e1b1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define functions for evaluating retrieval performance\n",
    "def map_at_k(true_ids, predicted_ids, k=10):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Average Precision at K (MAP@K).\n",
    "\n",
    "    Parameters:\n",
    "    true_ids (list): List of relevant product IDs.\n",
    "    predicted_ids (list): List of predicted product IDs.\n",
    "    k (int): Number of top elements to consider.\n",
    "             NOTE: IF you wish to change top k, please provide a justification for choosing the new value\n",
    "\n",
    "    Returns:\n",
    "    float: MAP@K score.\n",
    "    \"\"\"\n",
    "    # if either list is empty, return 0\n",
    "    if not len(true_ids) or not len(predicted_ids):\n",
    "        return 0.0\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p_id in enumerate(predicted_ids[:k]):\n",
    "        if p_id in true_ids and p_id not in predicted_ids[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "\n",
    "    return score / min(len(true_ids), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fc51ce2-521c-428c-8475-57fbc7145d77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please add any new evaluation functions here\n",
    "def weighted_map_at_k(\n",
    "        exact_match_ids: List[int], partial_match_ids: List[int], retrieval_ids: List[int], \n",
    "        k: int = 10\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Weighted Mean Average Precision at K (Weighted MAP@K).\n",
    "\n",
    "    Parameters:\n",
    "    exact_match_ids (list): List of IDs of exact matches.\n",
    "    partial_match_ids (list): List of IDs of partial matches.\n",
    "    retrieval_ids (list): List of retrieved IDs, ordered by rank.\n",
    "    k (int): Number of top elements to consider.\n",
    "\n",
    "    Returns:\n",
    "    float: Weighted MAP@K score.\n",
    "    \"\"\"\n",
    "    if not retrieval_ids:\n",
    "        return 0.0\n",
    "\n",
    "    score = 0.0\n",
    "    weighted_num_hits = 0.0\n",
    "    exact_match_weight = 1.0\n",
    "    partial_match_weight = 0.5\n",
    "\n",
    "    seen_ids = set()\n",
    "\n",
    "    for i, retrieved_id in enumerate(retrieval_ids[:k]):\n",
    "        weight = 0.0\n",
    "        if retrieved_id in exact_match_ids:\n",
    "            weight = exact_match_weight\n",
    "        elif retrieved_id in partial_match_ids:\n",
    "            weight = partial_match_weight\n",
    "\n",
    "        if weight > 0 and retrieved_id not in seen_ids:\n",
    "            weighted_num_hits += weight\n",
    "            score += weighted_num_hits / (i + 1.0)\n",
    "            seen_ids.add(retrieved_id)\n",
    "\n",
    "    num_exact_relevant = len(set(exact_match_ids))\n",
    "    num_partial_relevant = len(set(partial_match_ids) - set(exact_match_ids))\n",
    "    total_relevant_weight = (\n",
    "        num_exact_relevant * exact_match_weight + num_partial_relevant * partial_match_weight\n",
    "    )\n",
    "\n",
    "    if total_relevant_weight == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return score / min(total_relevant_weight, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e6f66b3-37d1-48b0-a9f5-fb58003f4cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get search queries\n",
    "query_df = pd.read_csv(\"WANDS/dataset/query.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "041c7b89-1985-4dff-86e6-67353c96bdc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>query_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>salon chair</td>\n",
       "      <td>Massage Chairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>smart coffee table</td>\n",
       "      <td>Coffee &amp; Cocktail Tables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dinosaur</td>\n",
       "      <td>Kids Wall Décor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>turquoise pillows</td>\n",
       "      <td>Accent Pillows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>chair and a half recliner</td>\n",
       "      <td>Recliners</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                      query               query_class\n",
       "0         0                salon chair            Massage Chairs\n",
       "1         1         smart coffee table  Coffee & Cocktail Tables\n",
       "2         2                   dinosaur           Kids Wall Décor\n",
       "3         3          turquoise pillows            Accent Pillows\n",
       "4         4  chair and a half recliner                 Recliners"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d55b7820-00e2-4300-966c-8762d15fd407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get products\n",
    "product_df = pd.read_csv(\"WANDS/dataset/product.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0d9c2a5-8c89-41fe-94d4-b0d57a09ca3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_class</th>\n",
       "      <th>category hierarchy</th>\n",
       "      <th>product_description</th>\n",
       "      <th>product_features</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>solid wood platform bed</td>\n",
       "      <td>Beds</td>\n",
       "      <td>Furniture / Bedroom Furniture / Beds &amp; Headboa...</td>\n",
       "      <td>good , deep sleep can be quite difficult to ha...</td>\n",
       "      <td>overallwidth-sidetoside:64.7|dsprimaryproducts...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>all-clad 7 qt . slow cooker</td>\n",
       "      <td>Slow Cookers</td>\n",
       "      <td>Kitchen &amp; Tabletop / Small Kitchen Appliances ...</td>\n",
       "      <td>create delicious slow-cooked meals , from tend...</td>\n",
       "      <td>capacityquarts:7|producttype : slow cooker|pro...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>all-clad electrics 6.5 qt . slow cooker</td>\n",
       "      <td>Slow Cookers</td>\n",
       "      <td>Kitchen &amp; Tabletop / Small Kitchen Appliances ...</td>\n",
       "      <td>prepare home-cooked meals on any schedule with...</td>\n",
       "      <td>features : keep warm setting|capacityquarts:6....</td>\n",
       "      <td>208.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>all-clad all professional tools pizza cutter</td>\n",
       "      <td>Slicers, Peelers And Graters</td>\n",
       "      <td>Browse By Brand / All-Clad</td>\n",
       "      <td>this original stainless tool was designed to c...</td>\n",
       "      <td>overallwidth-sidetoside:3.5|warrantylength : l...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>baldwin prestige alcott passage knob with roun...</td>\n",
       "      <td>Door Knobs</td>\n",
       "      <td>Home Improvement / Doors &amp; Door Hardware / Doo...</td>\n",
       "      <td>the hardware has a rich heritage of delivering...</td>\n",
       "      <td>compatibledoorthickness:1.375 '' |countryofori...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                                       product_name  \\\n",
       "0           0                            solid wood platform bed   \n",
       "1           1                        all-clad 7 qt . slow cooker   \n",
       "2           2            all-clad electrics 6.5 qt . slow cooker   \n",
       "3           3       all-clad all professional tools pizza cutter   \n",
       "4           4  baldwin prestige alcott passage knob with roun...   \n",
       "\n",
       "                  product_class  \\\n",
       "0                          Beds   \n",
       "1                  Slow Cookers   \n",
       "2                  Slow Cookers   \n",
       "3  Slicers, Peelers And Graters   \n",
       "4                    Door Knobs   \n",
       "\n",
       "                                  category hierarchy  \\\n",
       "0  Furniture / Bedroom Furniture / Beds & Headboa...   \n",
       "1  Kitchen & Tabletop / Small Kitchen Appliances ...   \n",
       "2  Kitchen & Tabletop / Small Kitchen Appliances ...   \n",
       "3                         Browse By Brand / All-Clad   \n",
       "4  Home Improvement / Doors & Door Hardware / Doo...   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  good , deep sleep can be quite difficult to ha...   \n",
       "1  create delicious slow-cooked meals , from tend...   \n",
       "2  prepare home-cooked meals on any schedule with...   \n",
       "3  this original stainless tool was designed to c...   \n",
       "4  the hardware has a rich heritage of delivering...   \n",
       "\n",
       "                                    product_features  rating_count  \\\n",
       "0  overallwidth-sidetoside:64.7|dsprimaryproducts...          15.0   \n",
       "1  capacityquarts:7|producttype : slow cooker|pro...         100.0   \n",
       "2  features : keep warm setting|capacityquarts:6....         208.0   \n",
       "3  overallwidth-sidetoside:3.5|warrantylength : l...          69.0   \n",
       "4  compatibledoorthickness:1.375 '' |countryofori...          70.0   \n",
       "\n",
       "   average_rating  review_count  \n",
       "0             4.5          15.0  \n",
       "1             2.0          98.0  \n",
       "2             3.0         181.0  \n",
       "3             4.5          42.0  \n",
       "4             5.0          42.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Max length to embed is 4317'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(product_df.head())\n",
    "max_length_to_embed = product_df['product_name'].apply(len).max()\n",
    "max_length_to_embed += product_df['product_description'].apply(\n",
    "    lambda x: len(x) if isinstance(x, str) else 0\n",
    ").max()\n",
    "display(f'Max length to embed is {max_length_to_embed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61d75f84-1152-43c7-b2a0-422267ab2298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get manually labeled groundtruth lables\n",
    "label_df = pd.read_csv(\"WANDS/dataset/label.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07b8f157-2049-4cdb-afc4-62e546d59dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25434</td>\n",
       "      <td>Exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12088</td>\n",
       "      <td>Irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>42931</td>\n",
       "      <td>Exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2636</td>\n",
       "      <td>Exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>42923</td>\n",
       "      <td>Exact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  query_id  product_id       label\n",
       "0   0         0       25434       Exact\n",
       "1   1         0       12088  Irrelevant\n",
       "2   2         0       42931       Exact\n",
       "3   3         0        2636       Exact\n",
       "4   4         0       42923       Exact"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"The testing labels are ['Exact' 'Irrelevant' 'Partial']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(label_df.head())\n",
    "display(f\"The testing labels are {label_df['label'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fb9f7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot labels distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='label', data=label_df)\n",
    "plt.title('Distribution of Labels')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb0dbc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Exact 0.10972036599156985'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Partial 0.6281184674959734'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Irrelevant 0.26216116651245674'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute label ratios\n",
    "label_counts = label_df['label'].value_counts()\n",
    "size = label_df.shape[0]\n",
    "display(f\"Exact {label_counts['Exact']/size}\")\n",
    "display(f\"Partial {label_counts['Partial']/size}\")\n",
    "display(f\"Irrelevant {label_counts['Irrelevant']/size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59768978-5c40-45b0-84a7-d6cc5d469b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group the labels for each query to use when identifying exact matches\n",
    "grouped_label_df = label_df.groupby('query_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1beab6d-1f59-427b-ad9f-1f0c6fcaadcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44307"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(42994, 44307)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate TF-IDF\n",
    "vectorizer, tfidf_matrix = calculate_tfidf(product_df)\n",
    "display(len(vectorizer.vocabulary_))\n",
    "display(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4400839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a function to retrieve top K product IDs for a query\n",
    "def get_top_product_ids_for_query(query):\n",
    "    top_product_indices = get_top_products(vectorizer, tfidf_matrix, query, top_n=10)\n",
    "    top_product_ids = product_df.iloc[top_product_indices]['product_id'].tolist()\n",
    "    return top_product_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e4b8333-b747-4c3e-87bc-4825f934ab6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top products for 'armchair':\n",
      "12756 24.41 '' wide tufted polyester armchair\n",
      "42698 donham armchair\n",
      "42697 donham 25 '' wide armchair\n",
      "41270 almaraz 33.7 '' wide leather match armchair\n",
      "23907 faizah 27.6 '' wide tufted polyester armchair\n",
      "31564 biloxi 34.75 '' wide armchair\n",
      "41306 hartsell 33 '' wide armchair\n",
      "1527 howington 39 '' wide tufted linen armchair\n",
      "42802 donham polyester lounge chair\n",
      "6532 ogan 29 '' wide polyester armchair\n"
     ]
    }
   ],
   "source": [
    "# Sanity check code block to see if the search results are relevant\n",
    "# Define the test query\n",
    "query = \"armchair\"\n",
    "\n",
    "# Obtain top product IDs\n",
    "top_product_ids = get_top_product_ids_for_query(query)\n",
    "\n",
    "print(f\"Top products for '{query}':\")\n",
    "for product_id in top_product_ids:\n",
    "    product = product_df.loc[product_df['product_id'] == product_id]\n",
    "    print(product_id, product['product_name'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bdeda61-7fb0-4ca6-a9e1-f1789b539f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Implementing a function to retrieve exact match product IDs for a query_id\n",
    "def get_matches_for_query(query_id: str, label: Literal['Exact', 'Irrelevant', 'Partial']) -> List[int]:\n",
    "    query_group = grouped_label_df.get_group(query_id)\n",
    "    exact_matches = query_group.loc[query_group['label'] == label]['product_id'].values\n",
    "    return exact_matches\n",
    "\n",
    "# Applying the function to obtain top product IDs and adding top K product IDs to the dataframe \n",
    "query_df['top_product_ids'] = query_df['query'].apply(get_top_product_ids_for_query)\n",
    "\n",
    "# Adding the list of exact match product_IDs from labels_df\n",
    "query_df['exact_match_ids'] = query_df['query_id'].apply(lambda x: get_matches_for_query(x, 'Exact'))\n",
    "query_df['partial_match_ids'] = query_df['query_id'].apply(lambda x: get_matches_for_query(x, 'Partial'))\n",
    "\n",
    "# Assign the map@k score\n",
    "query_df['map@k'] = query_df.apply(\n",
    "    lambda x: map_at_k(x['exact_match_ids'], x['top_product_ids'], k=10), axis=1\n",
    ")\n",
    "\n",
    "# Assign the weighted_map@k score\n",
    "query_df['weighted_map@k'] = query_df.apply(\n",
    "    lambda x: weighted_map_at_k(\n",
    "        x['exact_match_ids'], x['partial_match_ids'], x['top_product_ids'], k=10,\n",
    "    ), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed01f293-d87b-4ab0-811a-d39140ed5638",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Results of doing a lexical search with TF IDF:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'MAP at k=10 is 0.29'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Weighted MAP at k=10 is 0.46'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the MAP and Weighted MAP across the entire query set\n",
    "display('Results of doing a lexical search with TF IDF:')\n",
    "display(f\"MAP at k=10 is {query_df.loc[:, 'map@k'].mean():.2f}\")\n",
    "display(f\"Weighted MAP at k=10 is {query_df.loc[:, 'weighted_map@k'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f200289",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductID = NewType('ProductID', int)\n",
    "\n",
    "def calculate_embedding_matrix(\n",
    "        dataframe: pd.DataFrame\n",
    ") -> Tuple[SentenceTransformer, np.ndarray, List[ProductID]]:\n",
    "    \"\"\"\n",
    "    Calculate the embedding matrix for product content using SentenceTransformer with the \n",
    "    sentence embedding model Snowflake/snowflake-arctic-embed-m. The product content is chunked \n",
    "    because there are some products that may exceed the max amount of tokens that the sentence \n",
    "    embedding model is able to embed.\n",
    "    This method is optimized to just run one time, after the first computation of the embedding\n",
    "    matrix, the data is stored with pickle. Following executions will use the stored embedding \n",
    "    matrix.\n",
    "    Alongside the embedding matrix, a row-aligned list is returned, providing a mapping between \n",
    "    the row indices of the embedding matrix and their corresponding product IDs.\n",
    "    \n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): DataFrame with product information.\n",
    "    \n",
    "    Returns:\n",
    "    Tuple[SentenceTransformer, np.ndarray, List[ProductID]]: \n",
    "        - The SentenceTransformer model\n",
    "        - Matrix of all embeddings\n",
    "        - List mapping embedding indices to product IDs\n",
    "    \"\"\"\n",
    "    # Model selection\n",
    "    model = SentenceTransformer('Snowflake/snowflake-arctic-embed-m', trust_remote_code=True)\n",
    "    max_tokens = 512\n",
    "    \n",
    "    # Check if processed embeddings exist\n",
    "    if os.path.exists('product_embeddings_matrix.pkl'):\n",
    "        with open('product_embeddings_matrix.pkl', 'rb') as f:\n",
    "            saved_data = pickle.load(f)\n",
    "            return model, saved_data['embedding_matrix'], saved_data['product_id_map']\n",
    "    \n",
    "    # Initialize text splitter with 50% overlap\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=max_tokens*3,\n",
    "        chunk_overlap=(max_tokens*3)//2,  # 50% overlap\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    # Lists to hold all chunks and their corresponding product IDs\n",
    "    all_chunks = []\n",
    "    product_id_map = []  # Maps embedding index -> product_id\n",
    "    \n",
    "    # Process each product\n",
    "    for idx, row in dataframe.iterrows():\n",
    "        product_id = row['product_id']\n",
    "        combined_text = f\"{row['product_name']} {row['product_description']}\"\n",
    "        \n",
    "        # Split into chunks\n",
    "        chunks = text_splitter.split_text(combined_text)\n",
    "        \n",
    "        # Store chunks and product id\n",
    "        all_chunks.extend(chunks)\n",
    "        product_id_map.extend([product_id] * len(chunks))\n",
    "    \n",
    "    \n",
    "    # Convert chunks to embeddings in batches\n",
    "    batch_size = 256\n",
    "    embedding_list = []\n",
    "    \n",
    "    print(f\"Generating embeddings for {len(all_chunks)} chunks in {(len(all_chunks) // batch_size) + 1} batches\")\n",
    "    \n",
    "    for i in range(0, len(all_chunks), batch_size):\n",
    "        batch_chunks = all_chunks[i:i+batch_size]\n",
    "        batch_embeddings = model.encode(batch_chunks, show_progress=False)\n",
    "        embedding_list.append(batch_embeddings)\n",
    "        \n",
    "        if i % (batch_size * 10) == 0 and i > 0:\n",
    "            print(f\"Encoded {i}/{len(all_chunks)} chunks\")\n",
    "    \n",
    "    # Stack all embeddings into a single matrix\n",
    "    embedding_matrix = np.vstack(embedding_list)\n",
    "    \n",
    "    # Save for future use\n",
    "    with open('product_embeddings_matrix.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'embedding_matrix': embedding_matrix, \n",
    "            'product_id_map': product_id_map\n",
    "        }, f)\n",
    "    \n",
    "    return model, embedding_matrix, product_id_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dc22db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_products_ids_using_semantic_search(\n",
    "        model: SentenceTransformer, \n",
    "        embedding_matrix: np.ndarray, \n",
    "        product_id_map: List[int], \n",
    "        query: str, \n",
    "        top_n: int = 10\n",
    ") -> List[ProductID]:\n",
    "    \"\"\"\n",
    "    Get top products using semantic search.\n",
    "    \n",
    "    Parameters:\n",
    "    model: SentenceTransformer model\n",
    "    embedding_matrix: Matrix containing all chunk embeddings\n",
    "    product_id_map: List mapping embedding indices to product IDs\n",
    "    query: Search query\n",
    "    top_n: Number of top products to return\n",
    "    \n",
    "    Returns:\n",
    "    List of top product IDs\n",
    "    \"\"\"\n",
    "    # Encode query\n",
    "    query_embedding = model.encode([query], prompt_name=\"query\")[0]\n",
    "    \n",
    "    # Calculate cosine similarity between query and all embeddings\n",
    "    similarities = cosine_similarity(\n",
    "        query_embedding.reshape(1, -1),\n",
    "        embedding_matrix\n",
    "    )[0]\n",
    "    \n",
    "    # Create a mapping of product IDs to their highest similarity scores\n",
    "    product_similarities = {}\n",
    "    for idx, similarity in enumerate(similarities):\n",
    "        product_id = product_id_map[idx]\n",
    "        current_max = product_similarities.get(product_id, -1)\n",
    "        product_similarities[product_id] = max(current_max, similarity)\n",
    "    \n",
    "    # Sort products by similarity and return top_n\n",
    "    sorted_products = sorted(\n",
    "        product_similarities.items(),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    return [product_id for product_id, _ in sorted_products[:top_n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "202975da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/desposito/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "embedding_model, embedding_matrix, product_id_map = calculate_embedding_matrix(product_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08c9a2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top products for 'office chair':\n",
      "6982 office chair\n",
      "736 office chair - ergonomic computer chair for office - heavy duty faux leather office chair for home office workstation ( black )\n",
      "29213 eiladh home office computer task chair\n",
      "28687 office chair\n",
      "24145 office chair - ergonomic computer chair for office - heavy duty faux leather office chair for home office workstation ( black )\n",
      "29641 neumann task chair\n",
      "22126 merrisa swivel shell chair for living room/bed room , modern leisure office chair blue\n",
      "38394 aricijana office executive chair\n",
      "29629 heyer task chair\n",
      "12990 orean task chair\n"
     ]
    }
   ],
   "source": [
    "# Sanity check code block to see if the semantic search results are relevant\n",
    "# Define the test query\n",
    "query = \"office chair\"\n",
    "\n",
    "# Obtain top product IDs\n",
    "top_product_ids = get_top_products_ids_using_semantic_search(\n",
    "    embedding_model, embedding_matrix, product_id_map, query, top_n=10\n",
    ")\n",
    "\n",
    "print(f\"Top products for '{query}':\")\n",
    "for product_id in top_product_ids:\n",
    "    product = product_df.loc[product_df['product_id'] == product_id]\n",
    "    print(product_id, product['product_name'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b2f4681",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df['semantic_search_top_product_ids'] = query_df['query'].apply(\n",
    "    lambda query: get_top_products_ids_using_semantic_search(\n",
    "        embedding_model, embedding_matrix, product_id_map, query, top_n=10\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e34a5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the map@k score\n",
    "query_df['semantic_map@k'] = query_df.apply(\n",
    "    lambda x: map_at_k(x['exact_match_ids'], x['semantic_search_top_product_ids'], k=10), axis=1\n",
    ")\n",
    "\n",
    "# Assign the weighted_map@k score\n",
    "query_df['semantic_weighted_map@k'] = query_df.apply(\n",
    "    lambda x: weighted_map_at_k(\n",
    "        x['exact_match_ids'], x['partial_match_ids'], x['semantic_search_top_product_ids'], k=10,\n",
    "    ), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3db71c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Results of doing a semantic search with a sentence embedding model are:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'MAP at k=10 is 0.44'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Weighted MAP at k=10 is 0.58'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('Results of doing a semantic search with a sentence embedding model are:')\n",
    "display(f\"MAP at k=10 is {query_df.loc[:, 'semantic_map@k'].mean():.2f}\")\n",
    "display(f\"Weighted MAP at k=10 is {query_df.loc[:, 'semantic_weighted_map@k'].mean():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

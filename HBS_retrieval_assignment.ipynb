{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b781e47-2986-4c1d-b1f6-28361312aa93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: asttokens==3.0.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: certifi==2025.1.31 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (3.4.1)\n",
      "Requirement already satisfied: comm==0.2.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.2.2)\n",
      "Requirement already satisfied: contourpy==1.3.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: cycler==0.12.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: debugpy==1.8.13 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (1.8.13)\n",
      "Requirement already satisfied: decorator==5.2.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup==1.2.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (1.2.2)\n",
      "Requirement already satisfied: executing==2.2.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (2.2.0)\n",
      "Requirement already satisfied: filelock==3.18.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (3.18.0)\n",
      "Requirement already satisfied: fonttools==4.56.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 12)) (4.56.0)\n",
      "Requirement already satisfied: fsspec==2025.3.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 13)) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub==0.29.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 14)) (0.29.3)\n",
      "Requirement already satisfied: idna==3.10 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 15)) (3.10)\n",
      "Requirement already satisfied: importlib_metadata==8.6.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 16)) (8.6.1)\n",
      "Requirement already satisfied: importlib_resources==6.5.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 17)) (6.5.2)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 18)) (6.29.5)\n",
      "Requirement already satisfied: ipython==8.18.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 19)) (8.18.1)\n",
      "Requirement already satisfied: jedi==0.19.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 20)) (0.19.2)\n",
      "Requirement already satisfied: Jinja2==3.1.6 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 21)) (3.1.6)\n",
      "Requirement already satisfied: joblib==1.4.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 22)) (1.4.2)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 23)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 24)) (5.7.2)\n",
      "Requirement already satisfied: kiwisolver==1.4.7 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 25)) (1.4.7)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 26)) (3.0.2)\n",
      "Requirement already satisfied: matplotlib==3.9.4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 27)) (3.9.4)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 28)) (0.1.7)\n",
      "Requirement already satisfied: mpmath==1.3.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 29)) (1.3.0)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 30)) (1.6.0)\n",
      "Requirement already satisfied: networkx==3.2.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 31)) (3.2.1)\n",
      "Requirement already satisfied: numpy==2.0.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 32)) (2.0.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 33)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 34)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 35)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 36)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 37)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 38)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 39)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 40)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 41)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 42)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 43)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 44)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 45)) (12.4.127)\n",
      "Requirement already satisfied: packaging==24.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 46)) (24.2)\n",
      "Collecting pandas==2.2.2 (from -r requirements.txt (line 47))\n",
      "  Downloading pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: parso==0.8.4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 48)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 49)) (4.9.0)\n",
      "Requirement already satisfied: pillow==11.1.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 50)) (11.1.0)\n",
      "Requirement already satisfied: platformdirs==4.3.7 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 51)) (4.3.7)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.50 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 52)) (3.0.50)\n",
      "Requirement already satisfied: psutil==7.0.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 53)) (7.0.0)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 54)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 55)) (0.2.3)\n",
      "Requirement already satisfied: Pygments==2.19.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 56)) (2.19.1)\n",
      "Requirement already satisfied: pyparsing==3.2.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 57)) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 58)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz==2025.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 59)) (2025.1)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 60)) (6.0.2)\n",
      "Requirement already satisfied: pyzmq==26.3.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 61)) (26.3.0)\n",
      "Requirement already satisfied: regex==2024.11.6 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 62)) (2024.11.6)\n",
      "Requirement already satisfied: requests==2.32.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 63)) (2.32.3)\n",
      "Requirement already satisfied: safetensors==0.5.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 64)) (0.5.3)\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 65)) (1.6.1)\n",
      "Requirement already satisfied: scipy==1.13.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 66)) (1.13.1)\n",
      "Requirement already satisfied: seaborn==0.13.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 67)) (0.13.2)\n",
      "Requirement already satisfied: sentence-transformers==3.4.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 68)) (3.4.1)\n",
      "Requirement already satisfied: six==1.17.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 69)) (1.17.0)\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 70)) (0.6.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 71)) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl==3.6.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 72)) (3.6.0)\n",
      "Requirement already satisfied: tokenizers==0.21.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 73)) (0.21.1)\n",
      "Requirement already satisfied: torch==2.6.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 74)) (2.6.0)\n",
      "Requirement already satisfied: tornado==6.4.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 75)) (6.4.2)\n",
      "Requirement already satisfied: tqdm==4.67.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 76)) (4.67.1)\n",
      "Requirement already satisfied: traitlets==5.14.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 77)) (5.14.3)\n",
      "Requirement already satisfied: transformers==4.50.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 78)) (4.50.0)\n",
      "Requirement already satisfied: triton==3.2.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 79)) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 80)) (4.12.2)\n",
      "Requirement already satisfied: tzdata==2025.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 81)) (2025.2)\n",
      "Requirement already satisfied: urllib3==2.3.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 82)) (2.3.0)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 83)) (0.2.13)\n",
      "Requirement already satisfied: zipp==3.21.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 84)) (3.21.0)\n",
      "Collecting xformers==0.0.29.post3 (from -r requirements.txt (line 85))\n",
      "  Downloading xformers-0.0.29.post3-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
      "Downloading pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.29.post3-cp39-cp39-manylinux_2_28_x86_64.whl (43.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pandas, xformers\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.3\n",
      "    Uninstalling pandas-2.2.3:\n",
      "      Successfully uninstalled pandas-2.2.3\n",
      "Successfully installed pandas-2.2.2 xformers-0.0.29.post3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Python 3.9 required\n",
    "# Use GPU to speed up embedding matrix calculation. Alternative: download the embedding matrix \n",
    "# already calculated by me from \n",
    "# https://drive.google.com/file/d/1vcX7GuLn9hP9SKvQRpeP8WmWiWMPBmYW/view?usp=sharing and place it \n",
    "# at the same directory level as this notebook.\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e43e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/desposito/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List, Literal\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2384d13-941a-4c49-b903-68c5cf55ac15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'WANDS' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "#clone the git repo that contains the data and additional information about the dataset\n",
    "!git clone https://github.com/wayfair/WANDS.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42485468-77e2-4fc3-9a70-319a70603472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define functions for product search using Tf-IDF\n",
    "def calculate_tfidf(dataframe):\n",
    "    \"\"\"\n",
    "    Calculate the TF-IDF for combined product name and description.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): DataFrame with product_id, and other product information.\n",
    "\n",
    "    Returns:\n",
    "    TfidfVectorizer, csr_matrix: TF-IDF vectorizer and TF-IDF matrix.\n",
    "    \"\"\"\n",
    "    # Combine product name and description to vectorize\n",
    "    # NOTE: Please feel free to use any combination of columns available, some columns may contain NULL values\n",
    "    combined_text = dataframe['product_name'] + ' ' + dataframe['product_description']\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    # convert combined_text to list of unicode strings\n",
    "    tfidf_matrix = vectorizer.fit_transform(combined_text.values.astype('U'))\n",
    "    return vectorizer, tfidf_matrix\n",
    "\n",
    "def get_top_products(vectorizer, tfidf_matrix, query, top_n=10):\n",
    "    \"\"\"\n",
    "    Get top N products for a given query based on TF-IDF similarity.\n",
    "\n",
    "    Parameters:\n",
    "    vectorizer (TfidfVectorizer): Trained TF-IDF vectorizer.\n",
    "    tfidf_matrix (csr_matrix): TF-IDF matrix for the products.\n",
    "    query (str): Search query.\n",
    "    top_n (int): Number of top products to return.\n",
    "\n",
    "    Returns:\n",
    "    list: List of top N product IDs.\n",
    "    \"\"\"\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    cosine_similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "    top_product_indices = cosine_similarities.argsort()[-top_n:][::-1]\n",
    "    return top_product_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dd06913-4149-44c7-a876-787316e1b1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define functions for evaluating retrieval performance\n",
    "def map_at_k(true_ids, predicted_ids, k=10):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Average Precision at K (MAP@K).\n",
    "\n",
    "    Parameters:\n",
    "    true_ids (list): List of relevant product IDs.\n",
    "    predicted_ids (list): List of predicted product IDs.\n",
    "    k (int): Number of top elements to consider.\n",
    "             NOTE: IF you wish to change top k, please provide a justification for choosing the new value\n",
    "\n",
    "    Returns:\n",
    "    float: MAP@K score.\n",
    "    \"\"\"\n",
    "    #if either list is empty, return 0\n",
    "    if not len(true_ids) or not len(predicted_ids):\n",
    "        return 0.0\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p_id in enumerate(predicted_ids[:k]):\n",
    "        if p_id in true_ids and p_id not in predicted_ids[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "\n",
    "    return score / min(len(true_ids), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fc51ce2-521c-428c-8475-57fbc7145d77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Please add any new evaluation functions here\n",
    "def weighted_map_at_k(\n",
    "        exact_match_ids: List[int], partial_match_ids: List[int], retrieval_ids: List[int], \n",
    "        k: int = 10\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Weighted Mean Average Precision at K (Weighted MAP@K).\n",
    "\n",
    "    Parameters:\n",
    "    exact_match_ids (list): List of IDs of exact matches.\n",
    "    partial_match_ids (list): List of IDs of partial matches.\n",
    "    retrieval_ids (list): List of retrieved IDs, ordered by rank.\n",
    "    k (int): Number of top elements to consider.\n",
    "\n",
    "    Returns:\n",
    "    float: Weighted MAP@K score.\n",
    "    \"\"\"\n",
    "    if not retrieval_ids:\n",
    "        return 0.0\n",
    "\n",
    "    score = 0.0\n",
    "    weighted_num_hits = 0.0\n",
    "    exact_match_weight = 1.0\n",
    "    partial_match_weight = 0.5\n",
    "\n",
    "    seen_ids = set()\n",
    "\n",
    "    for i, retrieved_id in enumerate(retrieval_ids[:k]):\n",
    "        weight = 0.0\n",
    "        if retrieved_id in exact_match_ids:\n",
    "            weight = exact_match_weight\n",
    "        elif retrieved_id in partial_match_ids:\n",
    "            weight = partial_match_weight\n",
    "\n",
    "        if weight > 0 and retrieved_id not in seen_ids:\n",
    "            weighted_num_hits += weight\n",
    "            score += weighted_num_hits / (i + 1.0)\n",
    "            seen_ids.add(retrieved_id)\n",
    "\n",
    "    num_exact_relevant = len(set(exact_match_ids))\n",
    "    num_partial_relevant = len(set(partial_match_ids) - set(exact_match_ids))\n",
    "    total_relevant_weight = (\n",
    "        num_exact_relevant * exact_match_weight + num_partial_relevant * partial_match_weight\n",
    "    )\n",
    "\n",
    "    if total_relevant_weight == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return score / min(total_relevant_weight, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e6f66b3-37d1-48b0-a9f5-fb58003f4cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get search queries\n",
    "query_df = pd.read_csv(\"WANDS/dataset/query.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "041c7b89-1985-4dff-86e6-67353c96bdc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>query_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>salon chair</td>\n",
       "      <td>Massage Chairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>smart coffee table</td>\n",
       "      <td>Coffee &amp; Cocktail Tables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dinosaur</td>\n",
       "      <td>Kids Wall Décor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>turquoise pillows</td>\n",
       "      <td>Accent Pillows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>chair and a half recliner</td>\n",
       "      <td>Recliners</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                      query               query_class\n",
       "0         0                salon chair            Massage Chairs\n",
       "1         1         smart coffee table  Coffee & Cocktail Tables\n",
       "2         2                   dinosaur           Kids Wall Décor\n",
       "3         3          turquoise pillows            Accent Pillows\n",
       "4         4  chair and a half recliner                 Recliners"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d55b7820-00e2-4300-966c-8762d15fd407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get products\n",
    "product_df = pd.read_csv(\"WANDS/dataset/product.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0d9c2a5-8c89-41fe-94d4-b0d57a09ca3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_class</th>\n",
       "      <th>category hierarchy</th>\n",
       "      <th>product_description</th>\n",
       "      <th>product_features</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>solid wood platform bed</td>\n",
       "      <td>Beds</td>\n",
       "      <td>Furniture / Bedroom Furniture / Beds &amp; Headboa...</td>\n",
       "      <td>good , deep sleep can be quite difficult to ha...</td>\n",
       "      <td>overallwidth-sidetoside:64.7|dsprimaryproducts...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>all-clad 7 qt . slow cooker</td>\n",
       "      <td>Slow Cookers</td>\n",
       "      <td>Kitchen &amp; Tabletop / Small Kitchen Appliances ...</td>\n",
       "      <td>create delicious slow-cooked meals , from tend...</td>\n",
       "      <td>capacityquarts:7|producttype : slow cooker|pro...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>all-clad electrics 6.5 qt . slow cooker</td>\n",
       "      <td>Slow Cookers</td>\n",
       "      <td>Kitchen &amp; Tabletop / Small Kitchen Appliances ...</td>\n",
       "      <td>prepare home-cooked meals on any schedule with...</td>\n",
       "      <td>features : keep warm setting|capacityquarts:6....</td>\n",
       "      <td>208.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>all-clad all professional tools pizza cutter</td>\n",
       "      <td>Slicers, Peelers And Graters</td>\n",
       "      <td>Browse By Brand / All-Clad</td>\n",
       "      <td>this original stainless tool was designed to c...</td>\n",
       "      <td>overallwidth-sidetoside:3.5|warrantylength : l...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>baldwin prestige alcott passage knob with roun...</td>\n",
       "      <td>Door Knobs</td>\n",
       "      <td>Home Improvement / Doors &amp; Door Hardware / Doo...</td>\n",
       "      <td>the hardware has a rich heritage of delivering...</td>\n",
       "      <td>compatibledoorthickness:1.375 '' |countryofori...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                                       product_name  \\\n",
       "0           0                            solid wood platform bed   \n",
       "1           1                        all-clad 7 qt . slow cooker   \n",
       "2           2            all-clad electrics 6.5 qt . slow cooker   \n",
       "3           3       all-clad all professional tools pizza cutter   \n",
       "4           4  baldwin prestige alcott passage knob with roun...   \n",
       "\n",
       "                  product_class  \\\n",
       "0                          Beds   \n",
       "1                  Slow Cookers   \n",
       "2                  Slow Cookers   \n",
       "3  Slicers, Peelers And Graters   \n",
       "4                    Door Knobs   \n",
       "\n",
       "                                  category hierarchy  \\\n",
       "0  Furniture / Bedroom Furniture / Beds & Headboa...   \n",
       "1  Kitchen & Tabletop / Small Kitchen Appliances ...   \n",
       "2  Kitchen & Tabletop / Small Kitchen Appliances ...   \n",
       "3                         Browse By Brand / All-Clad   \n",
       "4  Home Improvement / Doors & Door Hardware / Doo...   \n",
       "\n",
       "                                 product_description  \\\n",
       "0  good , deep sleep can be quite difficult to ha...   \n",
       "1  create delicious slow-cooked meals , from tend...   \n",
       "2  prepare home-cooked meals on any schedule with...   \n",
       "3  this original stainless tool was designed to c...   \n",
       "4  the hardware has a rich heritage of delivering...   \n",
       "\n",
       "                                    product_features  rating_count  \\\n",
       "0  overallwidth-sidetoside:64.7|dsprimaryproducts...          15.0   \n",
       "1  capacityquarts:7|producttype : slow cooker|pro...         100.0   \n",
       "2  features : keep warm setting|capacityquarts:6....         208.0   \n",
       "3  overallwidth-sidetoside:3.5|warrantylength : l...          69.0   \n",
       "4  compatibledoorthickness:1.375 '' |countryofori...          70.0   \n",
       "\n",
       "   average_rating  review_count  \n",
       "0             4.5          15.0  \n",
       "1             2.0          98.0  \n",
       "2             3.0         181.0  \n",
       "3             4.5          42.0  \n",
       "4             5.0          42.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(product_df.head())\n",
    "display(product_df['product_name'].apply(len).max())\n",
    "display(product_df['product_description'].apply(lambda x: len(x) if isinstance(x, str) else 0).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61d75f84-1152-43c7-b2a0-422267ab2298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get manually labeled groundtruth lables\n",
    "label_df = pd.read_csv(\"WANDS/dataset/label.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07b8f157-2049-4cdb-afc4-62e546d59dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25434</td>\n",
       "      <td>Exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12088</td>\n",
       "      <td>Irrelevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>42931</td>\n",
       "      <td>Exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2636</td>\n",
       "      <td>Exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>42923</td>\n",
       "      <td>Exact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  query_id  product_id       label\n",
       "0   0         0       25434       Exact\n",
       "1   1         0       12088  Irrelevant\n",
       "2   2         0       42931       Exact\n",
       "3   3         0        2636       Exact\n",
       "4   4         0       42923       Exact"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(label_df.head())\n",
    "display(label_df['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fb9f7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='label', data=label_df)\n",
    "plt.title('Distribution of Labels')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb0dbc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Exact 0.10972036599156985'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Partial 0.6281184674959734'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Irrelevant 0.26216116651245674'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_counts = label_df['label'].value_counts()\n",
    "size = label_df.shape[0]\n",
    "display(f\"Exact {label_counts['Exact']/size}\")\n",
    "display(f\"Partial {label_counts['Partial']/size}\")\n",
    "display(f\"Irrelevant {label_counts['Irrelevant']/size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59768978-5c40-45b0-84a7-d6cc5d469b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#group the labels for each query to use when identifying exact matches\n",
    "grouped_label_df = label_df.groupby('query_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1beab6d-1f59-427b-ad9f-1f0c6fcaadcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44307"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(42994, 44307)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate TF-IDF\n",
    "vectorizer, tfidf_matrix = calculate_tfidf(product_df)\n",
    "display(len(vectorizer.vocabulary_))\n",
    "display(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e4b8333-b747-4c3e-87bc-4825f934ab6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top products for 'armchair':\n",
      "12756 24.41 '' wide tufted polyester armchair\n",
      "42698 donham armchair\n",
      "42697 donham 25 '' wide armchair\n",
      "41270 almaraz 33.7 '' wide leather match armchair\n",
      "23907 faizah 27.6 '' wide tufted polyester armchair\n",
      "31564 biloxi 34.75 '' wide armchair\n",
      "41306 hartsell 33 '' wide armchair\n",
      "1527 howington 39 '' wide tufted linen armchair\n",
      "42802 donham polyester lounge chair\n",
      "6532 ogan 29 '' wide polyester armchair\n"
     ]
    }
   ],
   "source": [
    "#Sanity check code block to see if the search results are relevant\n",
    "#implementing a function to retrieve top K product IDs for a query\n",
    "def get_top_product_ids_for_query(query):\n",
    "    top_product_indices = get_top_products(vectorizer, tfidf_matrix, query, top_n=10)\n",
    "    top_product_ids = product_df.iloc[top_product_indices]['product_id'].tolist()\n",
    "    return top_product_ids\n",
    "\n",
    "#define the test query\n",
    "query = \"armchair\"\n",
    "\n",
    "#obtain top product IDs\n",
    "top_product_ids = get_top_product_ids_for_query(query)\n",
    "\n",
    "print(f\"Top products for '{query}':\")\n",
    "for product_id in top_product_ids:\n",
    "    product = product_df.loc[product_df['product_id'] == product_id]\n",
    "    print(product_id, product['product_name'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bdeda61-7fb0-4ca6-a9e1-f1789b539f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#implementing a function to retrieve exact match product IDs for a query_id\n",
    "def get_matches_for_query(query_id: str, label: Literal['Exact', 'Irrelevant', 'Partial']) -> List[int]:\n",
    "    query_group = grouped_label_df.get_group(query_id)\n",
    "    exact_matches = query_group.loc[query_group['label'] == label]['product_id'].values\n",
    "    return exact_matches\n",
    "\n",
    "#applying the function to obtain top product IDs and adding top K product IDs to the dataframe \n",
    "query_df['top_product_ids'] = query_df['query'].apply(get_top_product_ids_for_query)\n",
    "\n",
    "#adding the list of exact match product_IDs from labels_df\n",
    "query_df['exact_match_ids'] = query_df['query_id'].apply(lambda x: get_matches_for_query(x, 'Exact'))\n",
    "query_df['partial_match_ids'] = query_df['query_id'].apply(lambda x: get_matches_for_query(x, 'Partial'))\n",
    "\n",
    "#assign the map@k score\n",
    "query_df['map@k'] = query_df.apply(\n",
    "    lambda x: map_at_k(x['exact_match_ids'], x['top_product_ids'], k=10), axis=1\n",
    ")\n",
    "\n",
    "#assign the weighted_map@k score\n",
    "query_df['weighted_map@k'] = query_df.apply(\n",
    "    lambda x: weighted_map_at_k(\n",
    "        x['exact_match_ids'], x['partial_match_ids'], x['top_product_ids'], k=10,\n",
    "    ), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed01f293-d87b-4ab0-811a-d39140ed5638",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.29319624944885364)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the MAP and Weighted MAP across the entire query set\n",
    "display(query_df.loc[:, 'map@k'].mean())\n",
    "display(query_df.loc[:, 'weighted_map@k'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f200289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embedding_matrix(dataframe: pd.DataFrame) -> Tuple[SentenceTransformer, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Calculate the embedding matrix for combined product name and description using SentenceTransformer.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): DataFrame with product information.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Embedding matrix.\n",
    "    \"\"\"\n",
    "    # Combine product name and description to vectorize\n",
    "    combined_text = dataframe['product_name'] + ' ' + dataframe['product_description']\n",
    "    #model = SentenceTransformer('intfloat/multilingual-e5-large-instruct')\n",
    "    model = SentenceTransformer('Snowflake/snowflake-arctic-embed-m-v2.0', trust_remote_code=True) # Max tokens 8192\n",
    "\n",
    "    # Load embedding matrix if available\n",
    "    if os.path.exists('embedding_matrix.npy'):\n",
    "        embedding_matrix = np.load('embedding_matrix.npy')\n",
    "        return model, embedding_matrix\n",
    "\n",
    "    # Convert combined_text to list of unicode strings\n",
    "    combined_text_list = combined_text.values.astype('U')\n",
    "\n",
    "    batch_size = 16\n",
    "\n",
    "    display(\n",
    "        f\"Start encoding {len(combined_text_list)} products with a batch size of {batch_size}. \"\n",
    "        f\"There are {(len(combined_text_list)//batch_size) + 1} batches.\"\n",
    "    )\n",
    "\n",
    "    embedding_matrix = []\n",
    "    for i in range(0, len(combined_text_list), batch_size):\n",
    "        start_time = time.time()\n",
    "        batch_embeddings = model.encode(\n",
    "            combined_text_list[i:i + batch_size], convert_to_tensor=False\n",
    "        )\n",
    "        embedding_matrix.extend(batch_embeddings)\n",
    "        end_time = time.time()\n",
    "        display(f\"Batch {i // batch_size + 1} took {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    # Save embedding matrix\n",
    "    np.save('embedding_matrix.npy', embedding_matrix)\n",
    "    return model, np.array(embedding_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7dc22db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_products_using_semantic_search(\n",
    "        model: SentenceTransformer, embedding_matrix: np.ndarray, query: str, top_n: int = 10\n",
    "):\n",
    "    query_vector = model.encode(\n",
    "        [query], prompt_name=\"query\", convert_to_tensor=False\n",
    "    )[0]\n",
    "\n",
    "    # Reshape query_vector to a 2D array\n",
    "    query_vector = query_vector.reshape(1, -1)\n",
    "\n",
    "    cosine_similarities = cosine_similarity(query_vector, embedding_matrix).flatten()\n",
    "    top_product_indices = cosine_similarities.argsort()[-top_n:][::-1]\n",
    "    return top_product_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "202975da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Snowflake/snowflake-arctic-embed-m-v2.0:\n",
      "- configuration_hf_alibaba_nlp_gte.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/Snowflake/snowflake-arctic-embed-m-v2.0:\n",
      "- modeling_hf_alibaba_nlp_gte.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Override attn_implementation='sdpa' to 'eager' as use_memory_efficient_attention='true'\n"
     ]
    }
   ],
   "source": [
    "embedding_model, embedding_matrix = calculate_embedding_matrix(product_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b2f4681",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "No operator found for `memory_efficient_attention_forward` with inputs:\n     query       : shape=(1, 7, 12, 64) (torch.float32)\n     key         : shape=(1, 7, 12, 64) (torch.float32)\n     value       : shape=(1, 7, 12, 64) (torch.float32)\n     attn_bias   : <class 'xformers.ops.fmha.attn_bias.BlockDiagonalMask'>\n     p           : 0.0\n`fa3F@v2.7.2.post1` is not supported because:\n    device=cpu (supported: {'cuda'})\n    dtype=torch.float32 (supported: {torch.bfloat16, torch.float16})\n`fa2F@v2.5.7-pt` is not supported because:\n    device=cpu (supported: {'cuda'})\n    dtype=torch.float32 (supported: {torch.bfloat16, torch.float16})\n`cutlassF-pt` is not supported because:\n    device=cpu (supported: {'cuda'})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     top_product_ids \u001b[38;5;241m=\u001b[39m product_df\u001b[38;5;241m.\u001b[39miloc[top_product_indices][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m top_product_ids\n\u001b[0;32m----> 6\u001b[0m query_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msemantic_search_top_product_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mquery_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_top_product_ids_for_query_using_semantic_search\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/pandas/core/series.py:4917\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m, in \u001b[0;36mget_top_product_ids_for_query_using_semantic_search\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_top_product_ids_for_query_using_semantic_search\u001b[39m(query):\n\u001b[0;32m----> 2\u001b[0m     top_product_indices \u001b[38;5;241m=\u001b[39m \u001b[43mget_top_products_using_semantic_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     top_product_ids \u001b[38;5;241m=\u001b[39m product_df\u001b[38;5;241m.\u001b[39miloc[top_product_indices][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m top_product_ids\n",
      "Cell \u001b[0;32mIn[26], line 11\u001b[0m, in \u001b[0;36mget_top_products_using_semantic_search\u001b[0;34m(model, embedding_matrix, query, top_n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_top_products_using_semantic_search\u001b[39m(\n\u001b[1;32m      2\u001b[0m         model: SentenceTransformer, embedding_matrix: np\u001b[38;5;241m.\u001b[39mndarray, query: \u001b[38;5;28mstr\u001b[39m, top_n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      3\u001b[0m ):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#    [instructed_query], convert_to_tensor=False, normalize_embeddings=True\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#)[0]\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     query_vector \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Reshape query_vector to a 2D array\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     query_vector \u001b[38;5;241m=\u001b[39m query_vector\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:623\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 623\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    625\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:690\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m     module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[1;32m    689\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py:442\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[39;00m\n\u001b[1;32m    436\u001b[0m trans_features \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    437\u001b[0m     key: value\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    440\u001b[0m }\n\u001b[0;32m--> 442\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# If the AutoModel is wrapped with a PeftModelForFeatureExtraction, then it may have added virtual tokens\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# We need to extend the attention mask to include these virtual tokens, or the pooling will fail\u001b[39;00m\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/Snowflake/snowflake-arctic-embed-m-v2.0/0d1661ceed1cb456c85726749d5be61ebb30d4f1/modeling_hf_alibaba_nlp_gte.py:939\u001b[0m, in \u001b[0;36mGteModel.forward\u001b[0;34m(self, input_ids, attention_mask, length, subset_indices, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, unpad_inputs)\u001b[0m\n\u001b[1;32m    929\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTODO: logn_attention_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m#     # attention scale log_512(input_len)\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;66;03m#     attention_scale = attention_mask.sum(1).log() / torch.tensor(self.config.max_position_embeddings).log()\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;66;03m#     # inference-time logn scale need clip 1\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;66;03m#     attention_scale = None\u001b[39;00m\n\u001b[0;32m--> 939\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrope_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrope_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unpad_inputs \u001b[38;5;129;01mand\u001b[39;00m output_padded:\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/Snowflake/snowflake-arctic-embed-m-v2.0/0d1661ceed1cb456c85726749d5be61ebb30d4f1/modeling_hf_alibaba_nlp_gte.py:748\u001b[0m, in \u001b[0;36mGteEncoder.forward\u001b[0;34m(self, hidden_states, attention_bias, rope_embeds, padding_inputs, attention_scale, subset_indices, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    737\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    738\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    739\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    745\u001b[0m         layer_head_mask,\n\u001b[1;32m    746\u001b[0m     )\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 748\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrope_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_subset_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/Snowflake/snowflake-arctic-embed-m-v2.0/0d1661ceed1cb456c85726749d5be61ebb30d4f1/modeling_hf_alibaba_nlp_gte.py:668\u001b[0m, in \u001b[0;36mGteLayer.forward\u001b[0;34m(self, hidden_states, attention_bias, rope_embeds, padding_inputs, attention_scale, subset_indices, head_mask, output_attentions, qkv_inputs)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    656\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;66;03m# Multi head self attention\u001b[39;00m\n\u001b[1;32m    667\u001b[0m     residual \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;28;01mif\u001b[39;00m qkv_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m qkv_inputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 668\u001b[0m     attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrope_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqkv_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqkv_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    678\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dropout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/Snowflake/snowflake-arctic-embed-m-v2.0/0d1661ceed1cb456c85726749d5be61ebb30d4f1/modeling_hf_alibaba_nlp_gte.py:500\u001b[0m, in \u001b[0;36mGteAttention.forward\u001b[0;34m(self, hidden_states, attention_bias, rope_embeds, padding_inputs, attention_scale, head_mask, output_attentions, qkv_inputs)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(attention_bias):\n\u001b[1;32m    499\u001b[0m         attention_bias \u001b[38;5;241m=\u001b[39m attention_bias\u001b[38;5;241m.\u001b[39mto(dtype)\n\u001b[0;32m--> 500\u001b[0m     context_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory_efficient_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, GteSdpaAttention):\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/xformers/ops/fmha/__init__.py:306\u001b[0m, in \u001b[0;36mmemory_efficient_attention\u001b[0;34m(query, key, value, attn_bias, p, scale, op, output_dtype)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmemory_efficient_attention\u001b[39m(\n\u001b[1;32m    195\u001b[0m     query: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    196\u001b[0m     key: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    203\u001b[0m     output_dtype: Optional[torch\u001b[38;5;241m.\u001b[39mdtype] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    204\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implements the memory-efficient attention mechanism following\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    `\"Self-Attention Does Not Need O(n^2) Memory\" <http://arxiv.org/abs/2112.05682>`_.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03m    :return: multi-head attention Tensor with shape ``[B, Mq, H, Kv]``\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_memory_efficient_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mInputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m            \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattn_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m            \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/xformers/ops/fmha/__init__.py:467\u001b[0m, in \u001b[0;36m_memory_efficient_attention\u001b[0;34m(inp, op)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_memory_efficient_attention\u001b[39m(\n\u001b[1;32m    463\u001b[0m     inp: Inputs, op: Optional[AttentionOp] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    464\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# fast-path that doesn't require computing the logsumexp for backward computation\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(x\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [inp\u001b[38;5;241m.\u001b[39mquery, inp\u001b[38;5;241m.\u001b[39mkey, inp\u001b[38;5;241m.\u001b[39mvalue]):\n\u001b[0;32m--> 467\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_memory_efficient_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m            \u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mop\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m     output_shape \u001b[38;5;241m=\u001b[39m inp\u001b[38;5;241m.\u001b[39mnormalize_bmhk()\n\u001b[1;32m    473\u001b[0m     op_fw \u001b[38;5;241m=\u001b[39m _serialize_op(op[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/xformers/ops/fmha/__init__.py:486\u001b[0m, in \u001b[0;36m_memory_efficient_attention_forward\u001b[0;34m(inp, op)\u001b[0m\n\u001b[1;32m    484\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m inp\u001b[38;5;241m.\u001b[39mnormalize_bmhk()\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_dispatch_fw\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     _ensure_op_supports_or_raise(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_efficient_attention\u001b[39m\u001b[38;5;124m\"\u001b[39m, op, inp)\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/xformers/ops/fmha/dispatch.py:135\u001b[0m, in \u001b[0;36m_dispatch_fw\u001b[0;34m(inp, needs_gradient)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_dispatch_fw\u001b[39m(inp: Inputs, needs_gradient: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Type[AttentionFwOpBase]:\n\u001b[1;32m    127\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Computes the best operator for forward\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    Raises:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m        AttentionOp: The best operator for the configuration\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_run_priority_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_efficient_attention_forward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_dispatch_fw_priority_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneeds_gradient\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Entrevistas/hbs-assignment/.venv/lib/python3.9/site-packages/xformers/ops/fmha/dispatch.py:76\u001b[0m, in \u001b[0;36m_run_priority_list\u001b[0;34m(name, priority_list, inp, extra_op_reasons)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m op, not_supported \u001b[38;5;129;01min\u001b[39;00m extra_op_reasons:\n\u001b[1;32m     75\u001b[0m         msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m _format_not_supported_reasons(op, not_supported)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: No operator found for `memory_efficient_attention_forward` with inputs:\n     query       : shape=(1, 7, 12, 64) (torch.float32)\n     key         : shape=(1, 7, 12, 64) (torch.float32)\n     value       : shape=(1, 7, 12, 64) (torch.float32)\n     attn_bias   : <class 'xformers.ops.fmha.attn_bias.BlockDiagonalMask'>\n     p           : 0.0\n`fa3F@v2.7.2.post1` is not supported because:\n    device=cpu (supported: {'cuda'})\n    dtype=torch.float32 (supported: {torch.bfloat16, torch.float16})\n`fa2F@v2.5.7-pt` is not supported because:\n    device=cpu (supported: {'cuda'})\n    dtype=torch.float32 (supported: {torch.bfloat16, torch.float16})\n`cutlassF-pt` is not supported because:\n    device=cpu (supported: {'cuda'})"
     ]
    }
   ],
   "source": [
    "def get_top_product_ids_for_query_using_semantic_search(query):\n",
    "    top_product_indices = get_top_products_using_semantic_search(embedding_model, embedding_matrix, query, top_n=10)\n",
    "    top_product_ids = product_df.iloc[top_product_indices]['product_id'].tolist()\n",
    "    return top_product_ids\n",
    "\n",
    "query_df['semantic_search_top_product_ids'] = query_df['query'].apply(get_top_product_ids_for_query_using_semantic_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e34a5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign the weighted_map@k score\n",
    "query_df['semantic_weighted_map@k'] = query_df.apply(\n",
    "    lambda x: weighted_map_at_k(\n",
    "        x['exact_match_ids'], x['partial_match_ids'], x['semantic_search_top_product_ids'], k=10,\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "#assign the map@k score\n",
    "query_df['semantic_map@k'] = query_df.apply(\n",
    "    lambda x: map_at_k(x['exact_match_ids'], x['semantic_search_top_product_ids'], k=10), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3db71c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.42508602246840094)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5756416075244201)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(query_df.loc[:, 'semantic_map@k'].mean())\n",
    "display(query_df.loc[:, 'semantic_weighted_map@k'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
